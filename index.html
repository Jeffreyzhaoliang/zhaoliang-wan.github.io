<!DOCTYPE html>
<html>

<head>
    <meta charset="UTF-8" />
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro:wght@200;300;400;600;700;900&display=swap"
        rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="assets/css/style.css" />
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-LDSQMLZ3GJ"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-LDSQMLZ3GJ');
    </script> -->
    <title> Zhaoliang Wan </title>
</head>

<body>
    <div style="width:1000px;margin: 0px auto;">
        <header id="header" width="400px" style="display:flex;justify-content: space-around;">
            <a href="#profile-intro">Home</a>
            <a href="#updates">Updates</a>
            <a href="#research">Research</a>
            <!-- <a href="#projects">Projects</a> -->
        </header>
        <div id="profile">
            <div id="profile-pic">
                <img src="assets/images/profile.jpg" />
            </div>
            <div id="profile-intro">
                <div id="profile-name">Zhaoliang Wan 万兆亮</div>
                <div id="profile-email">wanzhaoliang [at] insta360 (dot) com</div>
<!--                 <p> -->
<!--                    I’m a researcher at <a href="https://www.insta360.com/">Insta 360</a> working on multi-modal large language models (MLLMs), panoramic perception, and embodied intelligence. -->
                <p>
                I’m a researcher at <a href="https://www.insta360.com/">Insta360</a> working on multimodal foundation models and generalist robot autonomy. 
                </p>
                <p>
                Previously, I earned my Ph.D. in Computer Science from Sun Yat-sen University, gratefully advised by 
                <a href="https://cse.sysu.edu.cn/teacher/ChengHui">Prof. Hui Cheng</a> and co-advised by 
                <a href="http://people.ucas.edu.cn/~XuYang">Assoc. Prof. Xu Yang</a>, where I focused on dexterous manipulation and interactive perception.
                </p>
<!--                 <p>
                    Previously, I earned my Ph.D. in Computer Science from Sun Yat-sen University, where my work centered on dexterous manipulation and interactive perception.
                </p> -->
<!--                 <p> -->
                    <!--                     I earned my Ph.D. in Computer Science from Sun Yat-sen University, gratefully advised by Prof. <a href="https://cse.sysu.edu.cn/teacher/ChengHui">Hui Cheng</a> 
                    and co-advised by Assoc. Prof. <a href="http://people.ucas.edu.cn/~XuYang">Xu Yang</a>.
                    
<!--                     I have always been fascinated by the interaction between universal robots and the real world. 
                    Before coming to SYSU, I explored the design and autonomous grasping of underwater robots.
                    My research will focus on dexterous manipulation and interactive perception. -->
<!--                     I am passionate about robotics, particularly how robots interact with the real world. 
                    Before starting my PhD, I explored the design and autonomous grasping of underwater robots. 
                    My current research focuses on dexterous manipulation and interactive perception.  -->
<!--                 </p> -->

                <p>
                    Intern positions are open, with sufficient compute resources (GPUs) available. 
                    Feel free to reach out if you are passionate about multimodal large language models and robotics.
<!--                     Fitness helps me stay vigorous and inspires me to push my limits.
                    Recently, I have been practicing tennis in my free time. -->
                </p>
                <div>
<!--                     <a href="https://scholar.google.com/citations?user=hdvgN0cAAAAJ&hl=zh-CN">
                      Google Scholar
                    </a>
                    /
                    <a href="https://twitter.com/zhaoliang_wan">
                      Twitter
                    </a> -->
<!--                     /
                    <a href="https://github.com/Jeffreyzhaoliang?tab=repositories">
                      Github
                    </a> -->
                    </a>
                </div>
            </div>
            <div style="clear: both;"></div>
        </div>
        <div class="section" id="updates">
            <h1>Updates</h1>
            <ul>
                <li> <b>July 2025</b> I finished my PhD at SYSU.
                <li> <b>Jun 2025</b> One paper accepted to IROS 2025.
                <li> <b>Feb 2025</b> One paper accepted to CVPR 2025.
                <li> <b>Jun 2024</b> One paper accepted to IROS 2024.
                <li> <b>May 2024</b> One paper accepted to ICML 2024.
                <li> <b>Mar 2024</b>   I finished my research internship at Tencent, Robotics X.
<!--                 <li> <b>May 2024</b> <a>VinT-6D</a> has been accepted to <a>ICML 2024</a> -->
<!--                 <li> <b>Oct 2022</b>   I started my research internship at Tencent, Robotics X. -->
<!--                 <li> <b>May 2022</b> One paper accepted to ICRA 2022. -->
<!--                 <li> <b>Sep 2021</b> I started my PhD at SYSU. -->
<!--                 <li> <b>Mar 2021</b> I received my MS at Harbin Engineering University (HEU).</li>
                <li> <b>Sep 2018</b> I started my MS of joint-supervision at HEU and CASIA, advised by Prof. <a href="http://homepage.hrbeu.edu.cn/web/huanghai">Hai Huang</a> and <a href="http://people.ucas.edu.cn/~XuYang">Xu Yang</a>.
                <li> <b>Jun 2018</b> I received my BS at HEU.
                <li> <b>Jan 2018</b> I started visiting students at the State Key Laboratory of Management and Control for Complex Systems at CASIA.. -->
            </ul>
            <p></p>
            <div style="clear: both;"></div>
        </div>
        <div class="divider"></div>
        <div style="display:flex;flex-direction: column;">
            <h1>Research</h1>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/RSS_25.gif"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    RAPID Hand:  A <u>R</u>obust, <u>A</u>ffordable, <u>P</u>erception-<u>I</u>ntegrated, <u>D</u>exterous Platform for Generalist Robot Autonomy
                </a>
                <p>
                    <b>Zhaoliang Wan</b>, Zetong Bi, Zida Zhou, Hao Ren, Yiming Zeng, Li Yihan, Cao He, Lu Qi, Xu Yang, Ming-Hsuan Yang, Hui Cheng
                    <br>Under reviewing, May 2025 <br>
                    <a href="https://www.arxiv.org/abs/2506.07490">Paper</a> <a href="https://rapid-hand.github.io/">Project</a>
                </p>
            </div>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/rapid_hand_2.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    RAPID Hand Prototype: Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation
                </a>
                <p>
                    <b>Zhaoliang Wan</b>, Zida Zhou, Zetong Bi, Zehui Yang, Hao Ding, Hui Cheng
                    <br>IEEE International Conference on Intelligent Robots and Systems (IROS), Oct 2025 <br>
<!--                     <a href="">Paper</a> -->
                </p>
            </div>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/cvpr_25.gif"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    Prior Does Matter: Visual Navigation via Denoising Diffusion Bridge Models
                </a>
                <p>
                    Hao Ren, Yiming Zeng, Zetong Bi, <b>Zhaoliang Wan</b>, Junlong Huang, Hui Cheng
                    <br>The IEEE / CVF Computer Vision and Pattern Recognition Conference (CVPR), Feb 2025 <br>
                    <a href="https://arxiv.org/abs/2504.10041">Paper</a>     <a href="https://github.com/hren20/NaiviBridger">Project</a>
                </p>
            </div>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/IROS_24.gif"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    OPG-Policy: Occluded Push-Grasp Policy Learning with Amodal Segmentation
                </a>
                <p>
                    Hao Ding, Yiming Zeng, <b>Zhaoliang Wan</b>, Hui Cheng
                    <br>IEEE International Conference on Intelligent Robots and Systems (IROS), Oct 2024<br>
                    <a>Paper</a>    <a href="https://www.bilibili.com/video/BV1nT42167jX/?spm_id_from=333.999.0.0&vd_source=4819dbf51d95ed91db69568e345b8518">Video</a>
                </p>
            </div>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/bartender_git.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    VinT-6D: A Large-Scale Object-in-hand Dataset from Vision, Touch, and Proprioception
                </a>
                <p>
                     <b>Zhaoliang Wan</b>, Yonggen Ling, Senlin Yi, Lu Qi, Wangwei Lee, Minglei Lu, Sicheng Yang, Peng Lu, Xu Yang, Ming-Hsuan Yang, Hui Cheng    
                    <br>International Conference on Machine Learning (ICML), July 2024<br>
                    <a href="https://proceedings.mlr.press/v235/wan24d.html">Paper</a> 
                </p>
            </div>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/IJHR_2023.gif"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    Tracking Object's Pose via Dynamic Tactile Interaction
                </a>
                <p>
                    Qiguang Lin, Qiang Li, Yonggen Ling, Yu Zheng, Wangwei Lee, <b>Zhaoliang Wan</b>, Bidan Huang
                    <br>International Journal of Humanoid Robotics (IJHR), Oct 2023<br>
                    <a href="https://www.worldscientific.com/doi/epdf/10.1142/S0219843623500214">Paper</a>
                </p>
            </div>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/ijhr.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    Tactile-Based Object Pose Estimation Employing Extended Kalman Filter
                </a>
                <p>
                    Qiguang Lin, Qiang Li, Yonggen Ling, Yu Zheng, Wangwei Lee, <b>Zhaoliang Wan</b>, Bidan Huang
                    <br>IEEE International Conference on Advanced Robotics and Mechatronics (ICARM), July 2023<br>
                    <a href="https://ieeexplore.ieee.org/abstract/document/10218914">Paper</a>
                </p>
            </div>
            <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/ICRA_22.gif"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                    Uncertainty-based Exploring Strategy in Densely Cluttered Scenes for Vacuum Cup Grasping
                </a>
                <p>
                    Kimwa Tung, Jingcheng Su, Junhao Cai, <b>Zhaoliang Wan</b>, Hui Cheng
                    <br>IEEE International Conference on Robotics and Automation (ICRA), May 2022<br>
                    <a href="https://ieeexplore.ieee.org/document/9811599">Paper</a>
                </p>
            </div>
<!--             <div>
                <a  style="height: 15em;" class="research-thumb">
                    <img src="assets/images/pr.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title">
                  CANet: Co-attention network for RGB-D semantic segmentation
                </a>
                <p>
                    Hao Zhou, Lu Qi, Hai Huang, Xu Yang, <b>Zhaoliang Wan</b>
                    <br>Pattern Recognition (PR), Jan 2022.<br>
                    <a href="https://www.sciencedirect.com/science/article/pii/S0031320321006440">Paper</a>
                </p>
            </div> -->
<!--             <div>
                <a style="height: 15em;" class="research-thumb">
                  <img src="assets/images/robotica.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title"> 
                  Intelligent Target Visual Tracking and Control Strategy for Open Frame Underwater Vehicles 
                </a>
                <p>
                    Chaoyu Sun, <b>Zhaoliang Wan</b>, Hai Huang, Xu Yang
                    <br>Robotica, Dec 2021.<br>
                    <a href="https://www.cambridge.org/core/journals/robotica/article/intelligent-target-visual-tracking-and-control-strategy-for-open-frame-underwater-vehicles/09D089852B15EE0BFB56ACA0FEFF3687">paper</a>
                </p>
            </div>
            <div>
                <a style="height: 15em;" class="research-thumb">
                  <img src="assets/images/iconip.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title"> 
                  GSDCN: A Customized Two-Stage Neural Network for Benthonic Organism Detection 
                </a>
                <p>
                    <b>Zhaoliang Wan</b>, Lu Zhang, Hai Huang, Xu Yang
                    <br>The 27th International Conference on Neural Information Processing (ICONIP), Nov 2020.<br>
                    <a href="https://link.springer.com/chapter/10.1007/978-3-030-63833-7_68">paper</a>
                </p>
            </div>
            <div>
                <a style="height: 15em;" class="research-thumb">
                  <img src="assets/images/accv.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title"> 
                  RGB-D co-attention network for semantic segmentation 
                </a>
                <p>
                    Hao Zhou, Lu Qi, <b>Zhaoliang Wan</b>, Hai Huang, Xu Yang
                    <br>The 14th Asian Conference on Computer Vision (ACCV), Oct 2020.<br>
                    <a href="https://openaccess.thecvf.com/content/ACCV2020/papers/Zhou_RGB-D_Co-attention_Network_for_Semantic_Segmentation_ACCV_2020_paper.pdf">paper</a>
                </p>
            </div> -->
<!--             <div>
                <a style="height: 15em;" class="research-thumb">
                  <img src="assets/images/icmhi.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title"> 
                  Deformable Deep Network Atherosclerotic Coronary Plaque Recognition of Oct Imaging 
                </a>
                <p>
                    Chaoyu Sun, Hai Huang, <b>Zhaoliang Wan</b>
                    <br>The 4th International Conference on Medical and Health Informatics (ICMHI), Aug 2020.<br>
                    <a href="https://dl.acm.org/doi/pdf/10.1145/3418094.3418107">paper</a>
                </p>
            </div> -->
<!--             <div>
                <a style="height: 15em;" class="research-thumb">
                  <img src="assets/images/robio.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title"> 
                  Autonomous Underwater Pipeline Tracking Control Based on Visual Images 
                </a>
                <p>
                    Zexing Zhou, Hailong Shen, Hai Huang, Hao Zhou, <b>Zhaoliang Wan</b>
                    <br>2018 IEEE International Conference on Robotics and Biomimetics (ROBIO), Dec 2018.<br>
                    <a href="https://dl.acm.org/doi/pdf/10.1145/3418094.3418107">paper</a>
                </p>
            </div> -->
<!--             <div>
                <a style="height: 15em;" class="research-thumb">
                  <img src="assets/images/access.png"
                        style=" margin-bottom:-10px;"
                        alt="">
                </a>
                <a class="research-proj-title"> 
                  Design and vision based autonomous capture of sea organism with absorptive type remotely operated vehicle 
                </a>
                <p>
                    Jiyong Li, Hao Zhou, Hai Huang, Xu Yang, <b>Zhaoliang Wan</b>
                    <br>IEEE Access, Nov 2018.<br>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8536382">paper</a>
                </p>
            </div> -->
            <!-- <div>
                <p>* indicates equal contribution</p>
            </div> -->

            <div style="clear: both;"></div>
        </div>
        <!-- <div class="divider"></div>
        <div style="display:flex;flex-direction: column;">
            <h1>Projects</h1>
            <div>
                <a href="soft-creatures/index.html" class="research-thumb"><img
                        src="soft-creatures/gifs/elizabeth-hickey-small.gif" alt=""></a>
                <a href="soft-creatures/index.html" class="research-proj-title">Coevolution of Morphology and Policy
                    Implicit Neural Functions</a>
                <p>
                    <b>Huy Ha</b><br>
                    <a href="https://github.com/huy-ha/coevolving-neural-networks">Github</a>,
                    <a href="soft-creatures/index.html">Website</a>
                </p>
            </div>
            <div style="clear: both;"></div>
        </div> -->
    </div>
    <!-- <script src="js/pixi.min.js"></script> -->
    <!-- <script src="js/profile-pic.js"></script> -->
</body>

</html>
